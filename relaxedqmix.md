---
layout: default
title: Relaxed QMIX
---

# Relaxed QMIX for PyMARL

Relaxed QMIX relaxes QMIXâ€™s strict monotonicity constraint, enabling richer cooperative strategies in **StarCraft II**. This work extends the PyMARL framework with architectural modifications to allow tactical retreats and sacrificial plays that vanilla QMIX cannot capture.

---

## ğŸš€ Highlights
- Implemented a **correction network** with double state re-injection and L2 regularization.  
- Tuned Îµ to interpolate between monotonic and flexible coordination.  
- Evaluated on **SMAC benchmarks** (`8m`, `2s3z`, `MMM2`, `Corridor`).  

---

## âš™ï¸ Implementation
Experiments were run on **Boston Universityâ€™s SCC** using NVIDIA V100 GPUs and SLURM.  
Key hyperparameters:
- Îµ-greedy exploration (1.0 â†’ 0.05)  
- Replay buffer: 5000  
- Target update: every 200 episodes  
- Optimizer: RMSProp (lr = 0.0005)  

---

## ğŸ“Š Results
- **8m & 2s3z** â†’ matched QMIX (~90% win rate).  
- **MMM2** â†’ RelaxedQMIX reached ~70% vs QMIXâ€™s 10%.  
- **Corridor** â†’ remained unsolved (0%).  

---

## ğŸŒŸ Impact
RelaxedQMIX demonstrates that **small architectural changes can significantly improve cooperative MARL performance**, especially in heterogeneous environments.

---

## ğŸ”— Links
- ğŸ’» [GitHub Repository](https://github.com/miruyoun/PyMARL_RL_Project)  
- ğŸ“„ [Read Full Paper (PDF)](assets/RelaxedQMIX_Paper.pdf)  
- ğŸ¥ [Video Demos](https://www.youtube.com/playlist?list=PLfNwQXb-4EYiBC-Hm0P8xQDTPxbTGFpBp)  

---
